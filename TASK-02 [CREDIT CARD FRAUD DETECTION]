import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_score,f1_score,recall_score
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt

# Load the dataset

data = pd.read_csv('Downloads/creditcard.csv')

# Separate features and labels

X = data.drop('Class', axis=1)
y = data['Class']


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features (normalize)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Handle class imbalance using oversampling
oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)

# Train a RandomForestClassifier
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred_rf = rf_model.predict(X_test)

# Train a Logistic Regression model
lr_model = LogisticRegression(random_state=42)
lr_model.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred_lr = lr_model.predict(X_test)

# Calculate accuracies
accuracy_rf = accuracy_score(y_test, y_pred_rf)
accuracy_lr = accuracy_score(y_test, y_pred_lr)
data.head()

# Plot the comparison
models = ['RandomForest', 'Logistic Regression']
accuracies = [accuracy_rf, accuracy_lr]

plt.bar(models, accuracies, color=['lightblue', 'lightgreen'])
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison between RandomForest and Logistic Regression')
plt.ylim(0, 1)  # Set the y-axis limit between 0 and 1
plt.show()


# Calculate and print accuracy
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy: {accuracy_rf:.4f}")

# Calculate and print confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix:\n", conf_matrix)

# Calculate and print classification report
class_report = classification_report(y_test, y_pred_rf)
print("Classification Report:\n", class_report)

# Calculate and print precision, recall, and F1 score
precision = precision_score(y_test, y_pred_rf)
recall = recall_score(y_test, y_pred_rf)
f1 = f1_score(y_test, y_pred_rf)

print(f"\nPrecision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

predictions = rf_model.predict(X_train)

# Display a summary of the predictions
fraudulent_count = sum(predictions)
genuine_count = len(predictions) - fraudulent_count

print(f"Total Transactions: {len(predictions)}")
print(f"Fraudulent Transactions: {fraudulent_count}")
print(f"Genuine Transactions: {genuine_count}")

# Plot a pie chart with a light red color
labels = ['Fraudulent Transactions', 'Genuine Transactions']
sizes = [fraudulent_count, genuine_count]
colors = ['#ffcccc', '#99ff99']  # Light red and light green colors
explode = (0.1, 0)  # explode the 1st slice (i.e., Fraudulent Transactions)

plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Distribution of Predicted Transactions')
plt.show()
